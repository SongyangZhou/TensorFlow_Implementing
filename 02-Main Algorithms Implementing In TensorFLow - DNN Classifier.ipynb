{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsu9zJsYpJvs0uRVFYfLD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SongyangZhou/TensorFlow_Implementing/blob/main/02-Main%20Algorithms%20Implementing%20In%20TensorFLow%20-%20DNN%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier in TensorFlow\n",
        "- Environment preparation"
      ],
      "metadata": {
        "id": "zLVO5qYMlFbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-F6UVZCMkWTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af799a9-efe5-400b-f650-c717c93b3fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "# make sure it is compatible with both Python 2 and Python 3\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load the data set and do some data preprocessing"
      ],
      "metadata": {
        "id": "gXLATH3Hs9kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "# the way to load a link file\n",
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "\n",
        "df_train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)# training dataset\n",
        "df_eval = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0) # test dataset\n",
        "\n",
        "# split predictors and label.\n",
        "x_train = df_train.drop(columns=['Species'])\n",
        "y_train = df_train['Species']\n",
        "x_eval = df_eval.drop(columns=['Species'])\n",
        "y_eval = df_eval['Species']\n",
        "\n",
        "print(x_train.head()) # Check the x_train. The lable \"survived\" is excluded.\n",
        "print(y_train.head()) # Check the y_train\n",
        "print(x_eval.head()) # Check the x_eval\n",
        "print(y_eval.head()) # Check the y_eval\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_eval.shape)\n",
        "print(y_eval.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bbk0nOFlmp8",
        "outputId": "e8a22d5e-544b-4e86-b5c0-ee97080f3652"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "\u001b[1m2194/2194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6us/step\n",
            "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
            "0          6.4         2.8          5.6         2.2\n",
            "1          5.0         2.3          3.3         1.0\n",
            "2          4.9         2.5          4.5         1.7\n",
            "3          4.9         3.1          1.5         0.1\n",
            "4          5.7         3.8          1.7         0.3\n",
            "0    2\n",
            "1    1\n",
            "2    2\n",
            "3    0\n",
            "4    0\n",
            "Name: Species, dtype: int64\n",
            "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
            "0          5.9         3.0          4.2         1.5\n",
            "1          6.9         3.1          5.4         2.1\n",
            "2          5.1         3.3          1.7         0.5\n",
            "3          6.0         3.4          4.5         1.6\n",
            "4          5.5         2.5          4.0         1.3\n",
            "0    1\n",
            "1    2\n",
            "2    0\n",
            "3    1\n",
            "4    1\n",
            "Name: Species, dtype: int64\n",
            "(120, 4)\n",
            "(120,)\n",
            "(30, 4)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for classification, the Keras require the labels to be converted into one-hot encoding.\n",
        "y_train_onehot = to_categorical(y_train, num_classes=3)\n",
        "y_eval_onehot = to_categorical(y_eval, num_classes=3)\n",
        "y_train_onehot[0:5,] # check the onehot ecoding result."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeXxLuoZq3tT",
        "outputId": "8c4c2415-252b-46e5-e79b-2e922fd8a5b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bulid and compile the model\n",
        "the num of neurons in each layer are somewhat heristic and based on experimentation. In some specific numbers may vary, now we don't need to care about that. They are hyperparameters we need to optimize in specific case."
      ],
      "metadata": {
        "id": "XbGW9GGQs3wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(x_train.shape[1],)), # define the first hidden layer and the input data shape of this layer.\n",
        "    Dense(64, activation='relu'), # 2nd hidden layer\n",
        "    Dense(32, activation='relu'), # 3rd hidden layer\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSssI6LVrWtP",
        "outputId": "cd1c4640-a604-4a74-c45f-1e00d277dc3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- train the model"
      ],
      "metadata": {
        "id": "bFOt7CVTJH2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train_onehot, epochs=100, batch_size=16, validation_data=(x_eval, y_eval_onehot))\n",
        "# in this case we use test dataset to validate the model we trained, it doesn't we use test dataset to train the model.\n",
        "# in practice, we usually devide our dataset into training set, dev set and test set. the dev set can be used for validation.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V0pfQCYJGmT",
        "outputId": "e636de16-53e1-4c30-f945-bbfad6de59c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.3108 - loss: 1.2369 - val_accuracy: 0.2667 - val_loss: 1.1025\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4430 - loss: 0.9770 - val_accuracy: 0.5333 - val_loss: 0.9240\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6815 - loss: 0.8378 - val_accuracy: 0.6667 - val_loss: 0.7882\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8141 - loss: 0.7012 - val_accuracy: 0.5667 - val_loss: 0.7180\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7087 - loss: 0.6018 - val_accuracy: 0.7667 - val_loss: 0.6193\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8706 - loss: 0.5522 - val_accuracy: 0.8000 - val_loss: 0.5543\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8102 - loss: 0.4606 - val_accuracy: 0.7000 - val_loss: 0.5184\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9331 - loss: 0.3972 - val_accuracy: 1.0000 - val_loss: 0.4168\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9466 - loss: 0.3870 - val_accuracy: 0.8000 - val_loss: 0.4305\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8900 - loss: 0.3305 - val_accuracy: 0.9667 - val_loss: 0.3522\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9094 - loss: 0.3254 - val_accuracy: 0.8667 - val_loss: 0.3647\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.2908 - val_accuracy: 0.9667 - val_loss: 0.2779\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.2587 - val_accuracy: 0.9333 - val_loss: 0.3086\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.2342 - val_accuracy: 0.9667 - val_loss: 0.2294\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9550 - loss: 0.2278 - val_accuracy: 0.9333 - val_loss: 0.2375\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.2118 - val_accuracy: 0.9667 - val_loss: 0.1981\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9582 - loss: 0.1738 - val_accuracy: 1.0000 - val_loss: 0.1731\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9767 - loss: 0.1606 - val_accuracy: 0.9333 - val_loss: 0.2259\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.1654 - val_accuracy: 0.9333 - val_loss: 0.1705\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8987 - loss: 0.2056 - val_accuracy: 0.9333 - val_loss: 0.2381\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.1766 - val_accuracy: 0.9667 - val_loss: 0.1304\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.1276 - val_accuracy: 0.9667 - val_loss: 0.1268\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9320 - loss: 0.1660 - val_accuracy: 0.9333 - val_loss: 0.1966\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9274 - loss: 0.1636 - val_accuracy: 0.9667 - val_loss: 0.1193\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.1564 - val_accuracy: 0.9333 - val_loss: 0.1562\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9486 - loss: 0.1540 - val_accuracy: 1.0000 - val_loss: 0.1050\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 0.1200 - val_accuracy: 0.9667 - val_loss: 0.1247\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.1257 - val_accuracy: 0.9667 - val_loss: 0.1035\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.0817 - val_accuracy: 0.9667 - val_loss: 0.0962\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0854 - val_accuracy: 1.0000 - val_loss: 0.0912\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.1285 - val_accuracy: 0.9333 - val_loss: 0.1752\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.1711 - val_accuracy: 0.9667 - val_loss: 0.0882\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9430 - loss: 0.1384 - val_accuracy: 0.9667 - val_loss: 0.0989\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0726 - val_accuracy: 1.0000 - val_loss: 0.0834\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.0998 - val_accuracy: 0.9667 - val_loss: 0.0962\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9846 - loss: 0.0742 - val_accuracy: 0.9667 - val_loss: 0.0794\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0881 - val_accuracy: 0.9667 - val_loss: 0.0829\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.0858 - val_accuracy: 0.9667 - val_loss: 0.0818\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9888 - loss: 0.0622 - val_accuracy: 0.9667 - val_loss: 0.0751\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9311 - loss: 0.1137 - val_accuracy: 0.9667 - val_loss: 0.1001\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0856 - val_accuracy: 0.9667 - val_loss: 0.0733\n",
            "Epoch 42/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.0905 - val_accuracy: 0.9667 - val_loss: 0.0950\n",
            "Epoch 43/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0767 - val_accuracy: 0.9667 - val_loss: 0.0715\n",
            "Epoch 44/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9646 - loss: 0.0776 - val_accuracy: 0.9667 - val_loss: 0.0919\n",
            "Epoch 45/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.1137 - val_accuracy: 0.9667 - val_loss: 0.0718\n",
            "Epoch 46/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9741 - loss: 0.0671 - val_accuracy: 0.9667 - val_loss: 0.0782\n",
            "Epoch 47/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9751 - loss: 0.0689 - val_accuracy: 1.0000 - val_loss: 0.0687\n",
            "Epoch 48/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9615 - loss: 0.1266 - val_accuracy: 0.9667 - val_loss: 0.0683\n",
            "Epoch 49/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.0998 - val_accuracy: 0.9333 - val_loss: 0.1100\n",
            "Epoch 50/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9658 - loss: 0.1164 - val_accuracy: 0.9667 - val_loss: 0.0660\n",
            "Epoch 51/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9500 - loss: 0.0789 - val_accuracy: 0.9667 - val_loss: 0.0758\n",
            "Epoch 52/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9683 - loss: 0.1062 - val_accuracy: 0.9667 - val_loss: 0.0659\n",
            "Epoch 53/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0639 - val_accuracy: 1.0000 - val_loss: 0.0645\n",
            "Epoch 54/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9449 - loss: 0.1236 - val_accuracy: 0.9667 - val_loss: 0.0757\n",
            "Epoch 55/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9762 - loss: 0.0673 - val_accuracy: 0.9667 - val_loss: 0.0637\n",
            "Epoch 56/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9448 - loss: 0.0861 - val_accuracy: 0.9667 - val_loss: 0.0708\n",
            "Epoch 57/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9746 - loss: 0.1065 - val_accuracy: 0.9667 - val_loss: 0.0735\n",
            "Epoch 58/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 0.0478 - val_accuracy: 1.0000 - val_loss: 0.0624\n",
            "Epoch 59/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.0567 - val_accuracy: 0.9667 - val_loss: 0.0612\n",
            "Epoch 60/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0783 - val_accuracy: 0.9667 - val_loss: 0.0637\n",
            "Epoch 61/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.0851 - val_accuracy: 0.9667 - val_loss: 0.0648\n",
            "Epoch 62/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0576 - val_accuracy: 0.9667 - val_loss: 0.0635\n",
            "Epoch 63/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0975 - val_accuracy: 0.9667 - val_loss: 0.0632\n",
            "Epoch 64/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0718 - val_accuracy: 0.9667 - val_loss: 0.0595\n",
            "Epoch 65/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0689 - val_accuracy: 0.9667 - val_loss: 0.0617\n",
            "Epoch 66/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0452 - val_accuracy: 0.9667 - val_loss: 0.0595\n",
            "Epoch 67/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9761 - loss: 0.0961 - val_accuracy: 0.9667 - val_loss: 0.0621\n",
            "Epoch 68/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.1015 - val_accuracy: 0.9667 - val_loss: 0.0634\n",
            "Epoch 69/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0544 - val_accuracy: 0.9667 - val_loss: 0.0703\n",
            "Epoch 70/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9578 - loss: 0.0961 - val_accuracy: 0.9667 - val_loss: 0.0834\n",
            "Epoch 71/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0479 - val_accuracy: 0.9667 - val_loss: 0.0658\n",
            "Epoch 72/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.0809 - val_accuracy: 0.9667 - val_loss: 0.0792\n",
            "Epoch 73/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9798 - loss: 0.0679 - val_accuracy: 0.9667 - val_loss: 0.0572\n",
            "Epoch 74/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0751 - val_accuracy: 0.9667 - val_loss: 0.0655\n",
            "Epoch 75/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9595 - loss: 0.0982 - val_accuracy: 0.9667 - val_loss: 0.0574\n",
            "Epoch 76/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9503 - loss: 0.0934 - val_accuracy: 0.9667 - val_loss: 0.0569\n",
            "Epoch 77/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0578 - val_accuracy: 0.9667 - val_loss: 0.0639\n",
            "Epoch 78/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0386 - val_accuracy: 0.9667 - val_loss: 0.0567\n",
            "Epoch 79/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0708 - val_accuracy: 1.0000 - val_loss: 0.0565\n",
            "Epoch 80/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.0751 - val_accuracy: 0.9667 - val_loss: 0.0577\n",
            "Epoch 81/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9580 - loss: 0.0778 - val_accuracy: 0.9667 - val_loss: 0.0922\n",
            "Epoch 82/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9720 - loss: 0.0961 - val_accuracy: 1.0000 - val_loss: 0.0562\n",
            "Epoch 83/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9539 - loss: 0.0771 - val_accuracy: 0.9667 - val_loss: 0.0567\n",
            "Epoch 84/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.0645 - val_accuracy: 0.9667 - val_loss: 0.0655\n",
            "Epoch 85/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9672 - loss: 0.1178 - val_accuracy: 0.9667 - val_loss: 0.0580\n",
            "Epoch 86/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9811 - loss: 0.0775 - val_accuracy: 0.9667 - val_loss: 0.0586\n",
            "Epoch 87/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0504 - val_accuracy: 0.9667 - val_loss: 0.0566\n",
            "Epoch 88/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0471 - val_accuracy: 0.9667 - val_loss: 0.0561\n",
            "Epoch 89/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.0916 - val_accuracy: 0.9667 - val_loss: 0.0574\n",
            "Epoch 90/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0680 - val_accuracy: 0.9667 - val_loss: 0.0558\n",
            "Epoch 91/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9812 - loss: 0.0856 - val_accuracy: 0.9667 - val_loss: 0.0564\n",
            "Epoch 92/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9834 - loss: 0.0651 - val_accuracy: 0.9667 - val_loss: 0.0561\n",
            "Epoch 93/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0435 - val_accuracy: 0.9667 - val_loss: 0.0565\n",
            "Epoch 94/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0583 - val_accuracy: 0.9667 - val_loss: 0.0559\n",
            "Epoch 95/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.0957 - val_accuracy: 0.9667 - val_loss: 0.0686\n",
            "Epoch 96/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.0691 - val_accuracy: 0.9667 - val_loss: 0.0573\n",
            "Epoch 97/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.1111 - val_accuracy: 0.9667 - val_loss: 0.0582\n",
            "Epoch 98/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0761 - val_accuracy: 0.9667 - val_loss: 0.0605\n",
            "Epoch 99/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9809 - loss: 0.0389 - val_accuracy: 0.9667 - val_loss: 0.0557\n",
            "Epoch 100/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9760 - loss: 0.0718 - val_accuracy: 0.9667 - val_loss: 0.0804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- evaluate the model with test dataset"
      ],
      "metadata": {
        "id": "SPskltvyLaX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evlauate the model with loss and accuarcy on the test dataset\n",
        "test_loss, test_acc = model.evaluate(x_eval, y_eval_onehot)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# predict. you can change another dataset instead of test dataset\n",
        "# the result is returned as the possibility of each class\n",
        "y_pred = model.predict(x_eval)\n",
        "print(y_pred[0:5,])\n",
        "# covert the possibility into exact class\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "print(y_pred_class[0:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03iP_v2-LgIV",
        "outputId": "c41c0b60-35ff-45a7-b0a0-d4a0b71a3559"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9667 - loss: 0.0804\n",
            "Test accuracy: 0.9666666388511658\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "[[1.3565519e-04 9.8905522e-01 1.0809111e-02]\n",
            " [1.2440381e-07 2.1639980e-02 9.7835988e-01]\n",
            " [9.9958354e-01 4.1640672e-04 6.9647560e-10]\n",
            " [7.8611731e-05 9.7769541e-01 2.2225985e-02]\n",
            " [2.0746895e-04 9.6679419e-01 3.2998316e-02]]\n",
            "[1 2 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we're all done for the common and basic classiciation processing in TensorFlow. Hope you enjoy it and leave a message if you like it."
      ],
      "metadata": {
        "id": "4Axtn4QrRVwb"
      }
    }
  ]
}